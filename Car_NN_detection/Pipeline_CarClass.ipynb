{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pipeline_CarClass.ipynb","provenance":[{"file_id":"1Fjxp6aMqLLNTusaXTzK_zbrxcKCI8ed9","timestamp":1587580185464}],"collapsed_sections":[],"authorship_tag":"ABX9TyMFeq6oOckaP9mmGqfZZw6n"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"x65AjzTwblCn"},"source":["import cv2\n","import numpy as np\n","import pandas as pd\n","from numpy import expand_dims\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from matplotlib import pyplot\n","from matplotlib.patches import Rectangle\n","from google.colab import drive\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LS85vhSGl_1Q"},"source":["from google.colab.patches import cv2_imshow\n","class BoundBox:\n","\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n","\t\tself.xmin = xmin\n","\t\tself.ymin = ymin\n","\t\tself.xmax = xmax\n","\t\tself.ymax = ymax\n","\t\tself.objness = objness\n","\t\tself.classes = classes\n","\t\tself.label = -1\n","\t\tself.score = -1\n"," \n","\tdef get_label(self):\n","\t\tif self.label == -1:\n","\t\t\tself.label = np.argmax(self.classes)\n"," \n","\t\treturn self.label\n"," \n","\tdef get_score(self):\n","\t\tif self.score == -1:\n","\t\t\tself.score = self.classes[self.get_label()]\n"," \n","\t\treturn self.score\n"," \n","def _sigmoid(x):\n","\treturn 1. / (1. + np.exp(-x))\n"," \n","def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n","    # Парсим выход YOLO v3\n","\tgrid_h, grid_w = netout.shape[:2]\n","\tnb_box = 3\n","\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n","\tnb_class = netout.shape[-1] - 5\n","\tboxes = []\n","\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n","\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n","\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n","\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n"," \n","\tfor i in range(grid_h*grid_w):\n","\t\trow = i / grid_w\n","\t\tcol = i % grid_w\n","\t\tfor b in range(nb_box):\n","\t\t\t# 4-ый элемент - вероятность того, что это фон\n","\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n","\t\t\tif(objectness.all() <= obj_thresh): continue\n","\t\t\t# первые 4 элемента - x, y, w, и h\n","\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n","\t\t\tx = (col + x) / grid_w\n","\t\t\ty = (row + y) / grid_h\n","\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w\n","\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h\n","\t\t\t# остальные элементы - вероятности принадлежности к одному из классов\n","\t\t\tclasses = netout[int(row)][col][b][5:]\n","\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n","\t\t\tboxes.append(box)\n","\treturn boxes\n"," \n","def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n","\tnew_w, new_h = net_w, net_h\n","\tfor i in range(len(boxes)):\n","\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n","\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n","\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n","\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n","\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n","\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n"," \n","def _interval_overlap(interval_a, interval_b):\n","\tx1, x2 = interval_a\n","\tx3, x4 = interval_b\n","\tif x3 < x1:\n","\t\tif x4 < x1:\n","\t\t\treturn 0\n","\t\telse:\n","\t\t\treturn min(x2,x4) - x1\n","\telse:\n","\t\tif x2 < x3:\n","\t\t\t return 0\n","\t\telse:\n","\t\t\treturn min(x2,x4) - x3\n"," \n","def bbox_iou(box1, box2):\n","\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n","\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n","\tintersect = intersect_w * intersect_h\n","\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n","\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n","\tunion = w1*h1 + w2*h2 - intersect\n","\treturn float(intersect) / union\n"," \n","def do_nms(boxes, nms_thresh):\n","\tif len(boxes) > 0:\n","\t\tnb_class = len(boxes[0].classes)\n","\telse:\n","\t\treturn\n","\tfor c in range(nb_class):\n","\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n","\t\tfor i in range(len(sorted_indices)):\n","\t\t\tindex_i = sorted_indices[i]\n","\t\t\tif boxes[index_i].classes[c] == 0: continue\n","\t\t\tfor j in range(i+1, len(sorted_indices)):\n","\t\t\t\tindex_j = sorted_indices[j]\n","\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n","\t\t\t\t\tboxes[index_j].classes[c] = 0\n"," \n","def prepare_frame(frame, shape):\n","  h,w,c = frame.shape\n","  pframe = cv2.resize(frame, shape)\n","  pframe = cv2.cvtColor(pframe,cv2.COLOR_BGR2RGB)\n","  pframe = pframe.astype(float)/255\n","  pframe = np.expand_dims(pframe, axis=0)\n","  return pframe, w, h\t\n"," \n","# получим все предсказания, превышающие заданный порог\n","def get_boxes(boxes, labels, thresh):\n","\tv_boxes, v_labels, v_scores = list(), list(), list()\n","\t\n","\tfor box in boxes:\t\t\n","\t\tfor i in range(len(labels)):\t\t\n","\t\t\tif labels[i] in [\"car\", \"bus\", \"truck\"]:\t\n","\t\t\t\tif box.classes[i] > thresh:\n","\t\t\t\t\tv_boxes.append(box)\n","\t\t\t\t\tv_labels.append(labels[i])\n","\t\t\t\t\tv_scores.append(box.classes[i]*100)\n","\t\t\t\t# не прерываем: одна ячейка может предсказать несколько классов\n","\treturn v_boxes, v_labels, v_scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCw7GlEOVoZD"},"source":["def cut_image(image, x1, x2, y1, y2, dim):  \n","  img = image[y1:y2, x1:x2]\n","  #cv2_imshow(img)\n","  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","  img = img.astype(float)/255\n","  #plt.imshow(img)\n","  #plt.show()\n","  width = img.shape[0]\n","  hight = img.shape[1]\n","  k = dim/max(hight,width)\n","  img = cv2.resize(img, (round(hight*k), round(width*k)))\n","  k1 = round(abs(img.shape[0]-img.shape[1])/2)\n","  k2 = abs(img.shape[0]-img.shape[1])-k1\n","  if width>hight:\n","    img = np.pad(img, ((0,0),(k1,k2),(0,0)), 'constant', constant_values=(0, 0))\n","  else:\n","    img = np.pad(img, ((k1,k2),(0,0),(0,0)), 'constant', constant_values=(0, 0))\n","    #plt.imshow(img)\n","    #plt.show()\n","  return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5DDOAExcsf6","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1587808453368,"user_tz":-300,"elapsed":41539,"user":{"displayName":"Александра Фоменко","photoUrl":"","userId":"14226277926344341766"}},"outputId":"250685da-155e-4e2f-ab1b-25b1c3312357"},"source":["drive.mount('/content/drive/')\n","# загружаем YOLO\n","model = load_model('/content/drive/My Drive/Colab Notebooks/CarsDetection/model/yolo_v3_model.h5')\n","\n","# определим размер входного изображения для модели\n","input_w, input_h = 416, 416"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v6DO9z7xzcnr"},"source":["# открываем видеоролик\n","cap = cv2.VideoCapture('/content/drive/My Drive/Colab Notebooks/CarsDetection/Data/Video/5.mp4')\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('output.avi',fourcc, 20.0, (1280,720))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MKeAVvJ3d-lN","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"error","timestamp":1587760950277,"user_tz":-300,"elapsed":31964,"user":{"displayName":"Александра Фоменко","photoUrl":"","userId":"14226277926344341766"}},"outputId":"a6b72504-1c20-4336-cae6-d70f071ab7f1"},"source":["from google.colab.patches import cv2_imshow\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.optimizers import Adam \n","from google.colab import files\n","\n","# загружаем модель по распознаванию типу транспортного средства\n","CarDetectionModel = load_model('/content/drive/My Drive/Colab Notebooks/CarsDetection/model/CNN_092.h5')\n","opt = Adam()\n","CarDetectionModel.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","n = 1\n","input_size = 50\n","arr = np.empty((1,input_size,input_size,3))\n","carclass = np.array([\"car\",\"truck\",\"bus\"])\n","while(n < 140):\n","    # Читаем по одному кадру, пока ролик не закончится\n","    ret, frame = cap.read()\n","\n","    print('frame ',n)\n","    if frame is None:\n","      break\n","    \n","    frame = cv2.resize(frame, (1280, 720))\n","    oldframe = np.copy(frame)\n","    image, image_w, image_h = prepare_frame(frame, (input_w, input_h))\n","    # выполняем детектирование объектов на кадре\n","    yhat = model.predict(image)\n","\n","    #print([a.shape for a in yhat])\n","    # определим анкоры\n","    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n","    # порог уверенности для вывода детектируемого объекта\n","    class_threshold = 0.6\n","    boxes = list()\n","    for i in range(len(yhat)):\t    \n","\t    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n","    \n","    correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n","    # используем Non-maximum supression для убирания лишних срабатываний на одни и те же объекты\n","    do_nms(boxes, 0.5)\n","    # определим метки классов\n","    labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n","\t    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n","\t    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n","\t    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n","\t    \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n","\t    \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n","\t    \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n","\t    \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n","\t    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n","\t    \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n","    \n","    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n","    \n","    #for i in range(len(v_boxes)):\n","        #print(v_labels[i], v_scores[i])\n","    \n","\t# рисуем боксы и выводим названия классов\n","    \n","    for i in range(len(v_boxes)):\n","        box = v_boxes[i]        \n","        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n","        if (x1 >= 0)&(y1 >= 0)&(x2 <= 1280)&(y2 <= 720)&((x2 - x1) > 0)&((y2 - y1) > 0):\n","          crop_image = cut_image(oldframe, x1, x2, y1, y2, input_size)\n","          arr[0] = crop_image\n","          #plt.imshow(arr[0])\n","          #plt.show()\n","          y = CarDetectionModel.predict(arr)\n","          k = np.argmax(y[0])\n","          #print('My class ',carclass[k],' Yolo class ',v_labels[i])\n","          #print('----------------------------------------------------------------------------')\n","          cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n","          text = 'M:'+str(carclass[k])+' Y:'+str(v_labels[i])\n","          cv2.putText(frame, text, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n","    #cv2_imshow(frame)\n","    out.write(frame)\n","    n+=1\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","    \n","cap.release()\n","cv2.destroyAllWindows()\n","cv2.waitKey(1)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["frame  1\n","frame  2\n","frame  3\n","frame  4\n","frame  5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zvgRTJvqsKq1"},"source":["from google.colab import files\n","files.download('output.avi')"],"execution_count":null,"outputs":[]}]}